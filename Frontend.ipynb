{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33f0ad88-7a8c-4250-b616-bef4bcac5d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import pickle\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS as fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0deb36-03ee-4413-ab5a-ab6005c871c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "from waybackpy import WaybackMachineCDXServerAPI\n",
    "from datetime import datetime\n",
    "from newspaper import Article\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977192b0-078e-4047-85ae-0493c7e7b3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter NVIDIA API KEY:  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\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ[\"NVIDIA_API_KEY\"] = input(\"Enter NVIDIA API KEY: \")\n",
    "\n",
    "#Load the model via NVIDIA API\n",
    "instruct_llm = ChatNVIDIA(model=\"meta/llama3-8b-instruct\")\n",
    "\n",
    "sys_msg0 = (\n",
    "    \"You are Pathwise, an AI bot that spots historical patterns/trends as it concerns improving an individuals financial situation, and notifies the user when the pattern has been spotted in the last week\"\n",
    "    \"You are currently trying to gather the following user information: {info}\"\n",
    "    \"Extract the information from the user input and {return_info}. If the information provided is invalid please return the word 'Invalid'\"\n",
    ")\n",
    "sys_msg1 = (\n",
    "    \"You are Pathwise, an AI bot that spots historical patterns/trends as it concerns improving an individuals financial situation, and notifies the user when the pattern has been spotted in the last week\"\n",
    "    \"You are currently trying to gather the following user information: {info}. The user has the following options to choose from: {options}. They are to provide only one number (1 to 5) in order to indicate their selection any other options are Invalid \"\n",
    "    \"Extract the information from the user input and {return_info}. If the information provided is invalid please return the word 'Invalid'\"\n",
    ")\n",
    "sys_msg2 = (\n",
    "    \"You are Pathwise, an AI bot that spots historical patterns/trends as it concerns improving an individuals financial situation, and notifies the user when the pattern has been spotted in the last week\"\n",
    "    \"You are currently trying to gather the following user information: {info}. The user has the following options to choose from: {options}. They are to provide only one number (1 or 2) in order to indicate their selection any other options are Invalid \"\n",
    "    \"Extract the information from the user input and {return_info}. If the information provided is invalid please return the word 'Invalid'\"\n",
    ")\n",
    "eg1_user = {}\n",
    "eg1_assist = {}\n",
    "eg2_user = {}\n",
    "eg2_assist = {}\n",
    "eg3_user = {}\n",
    "eg3_assist = {}\n",
    "return_info = {}\n",
    "options = {}\n",
    "user_profile = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54fce887-48be-4094-9895-1c7439dc460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_techcrunch_article(url):\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    return {\n",
    "        \"title\": article.title,\n",
    "        \"authors\": article.authors,\n",
    "        \"date\": article.publish_date,\n",
    "        \"body\": article.text\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71036ab0-e25e-4eb9-91f3-1f3d3979da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_techcrunch_rss(url = \"https://techcrunch.com/feed/\"):\n",
    "        \"\"\"Fetch latest fintech news headlines from TechCrunch RSS feed\"\"\"\n",
    "        articles = []\n",
    "        try:\n",
    "            feed = feedparser.parse(url)\n",
    "            for entry in feed.entries:\n",
    "                title = entry.get(\"title\", \"No Title\")\n",
    "                link = entry.get(\"link\", \"\")\n",
    "                articles.append((title, link))\n",
    "            print(f\"Fetched {len(articles)} news articles from TechCrunch\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch TechCrunch news: {e}\")\n",
    "        return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589f212d-08a9-490b-bf63-ad89aa66a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news():\n",
    "    directory = \"techcrunch\"\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    today = date.today()\n",
    "    \n",
    "    articles = fetch_techcrunch_rss()\n",
    "    links = [x[1] for x in articles]\n",
    "    if os.path.exists(f\"techcrunch/{today}-0.txt\"):\n",
    "        print(\"Already collected today's news.\")\n",
    "        return\n",
    "    \n",
    "    for i,x in enumerate(links):\n",
    "        url = links[i]\n",
    "        print(url)\n",
    "        article = scrape_techcrunch_article(url)\n",
    "        outfile = open(f\"techcrunch/{today}-{i}.txt\",\"w\")\n",
    "        outfile.write(article[\"body\"])\n",
    "        outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3ea55b0-1a54-4cc5-b664-33dfe41b03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_current_event_with_user_profile(event_file_path, user_profile_string):\n",
    "    \"\"\"\n",
    "    Simple concatenation of current event and user profile\n",
    "    \n",
    "    Args:\n",
    "        event_file_path: Path to text file containing one current event\n",
    "        user_profile_string: \"Age: 35, Location: NYC, Education: Masters, \n",
    "                            Skills: Python Programming, Free Time: 10hrs/week, \n",
    "                            Capital: $50000, Timeline: 5 years\"\n",
    "    \n",
    "    Returns:\n",
    "        Combined text ready for embedding\n",
    "    \"\"\"\n",
    "    # Read the current event\n",
    "    with open(event_file_path, 'r') as f:\n",
    "        current_event = f.read().strip()\n",
    "    \n",
    "    # Simple concatenation\n",
    "    combined_text = f\"Current Event: {current_event}\\n\\nUser Profile: {user_profile_string}\"\n",
    "    \n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddfc10f9-6d97-4918-8217-298a25353bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_current_events(current_events_folder, user_profile_string):\n",
    "    \"\"\"\n",
    "    Process all current event files with the user profile\n",
    "    \n",
    "    Returns:\n",
    "        List of combined texts ready for embedding\n",
    "    \"\"\"\n",
    "    combined_texts = []\n",
    "    \n",
    "    for filename in os.listdir(current_events_folder):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(current_events_folder, filename)\n",
    "            \n",
    "            combined_text = combine_current_event_with_user_profile(\n",
    "                file_path, \n",
    "                user_profile_string\n",
    "            )\n",
    "            \n",
    "            combined_texts.append({\n",
    "                'text': combined_text,\n",
    "                'source_file': filename,\n",
    "                'user_profile': user_profile_string\n",
    "            })\n",
    "    \n",
    "    return combined_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64081478-1579-442b-8078-0f11c16b7100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 7 - Returns a list of tuples containing the index of a historial store embedding, index of a current news embedding and a similarity score\n",
    "def get_similarity_scores(current_news_embeddings, historical_store):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between every current-news embedding\n",
    "    and every historical-store embedding.\n",
    "\n",
    "    Args:\n",
    "      current_news_embeddings: Sequence of arrays, shape [(d,), …]\n",
    "      historical_store:         Sequence of arrays, shape [(d,), …]\n",
    "\n",
    "    Returns:\n",
    "      List of tuples (hist_idx, curr_idx, score).\n",
    "    \"\"\"\n",
    "    # Ensure everything is an np.ndarray\n",
    "    current = [np.asarray(e, dtype=float) for e in current_news_embeddings]\n",
    "    historical = [np.asarray(e, dtype=float) for e in historical_store]\n",
    "\n",
    "    # Precompute norms\n",
    "    curr_norms = [np.linalg.norm(e) for e in current]\n",
    "    hist_norms = [np.linalg.norm(e) for e in historical]\n",
    "\n",
    "    scores = []\n",
    "    for curr_idx, curr_vec in enumerate(current):\n",
    "        for hist_idx, hist_vec in enumerate(historical):\n",
    "            # avoid division by zero\n",
    "            if curr_norms[curr_idx] == 0 or hist_norms[hist_idx] == 0:\n",
    "                sim = 0.0\n",
    "            else:\n",
    "                sim = np.dot(curr_vec, hist_vec) / (curr_norms[curr_idx] * hist_norms[hist_idx])\n",
    "            scores.append((hist_idx, curr_idx, sim))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5663c3b-1c64-4e8e-aac3-7b7eec7e7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 8 - Return a string with the top 3 recommend strategies \n",
    "def get_top3_strategies(financial_strategies, strategy_list):\n",
    "    \"\"\"\n",
    "    Select the top 3 recommended strategies based on similarity scores.\n",
    "\n",
    "    Args:\n",
    "        financial_strategies: List of tuples (hist_idx, curr_idx, score)\n",
    "        strategy_list:       List of strategy names (indexed by hist_idx)\n",
    "\n",
    "    Returns:\n",
    "        A string naming the top 3 strategies in descending order of score.\n",
    "    \"\"\"\n",
    "    # Sort by score descending\n",
    "    sorted_scores = sorted(financial_strategies, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Pick the top 3 unique historical indices\n",
    "    top_hist_idxs = []\n",
    "    for hist_idx, curr_idx, score in sorted_scores:\n",
    "        if hist_idx not in top_hist_idxs:\n",
    "            top_hist_idxs.append(hist_idx)\n",
    "        if len(top_hist_idxs) == 3:\n",
    "            break\n",
    "\n",
    "    # Map to strategy names\n",
    "    top_strategies = [strategy_list[i] for i in top_hist_idxs]\n",
    "\n",
    "    # Format the result string\n",
    "    if not top_strategies:\n",
    "        return \"No strategies available.\"\n",
    "    elif len(top_strategies) < 3:\n",
    "        return \"Top recommended strategies: \" + \", \".join(top_strategies)\n",
    "    else:\n",
    "        return \"Top 3 recommended strategies: \" + \", \".join(top_strategies)\n",
    "\n",
    "# Example usage:\n",
    "# financial_strategies = [(0, 0, 0.85), (2, 0, 0.80), (1, 0, 0.78), ...]\n",
    "# strategy_list = [\"Mean Reversion\", \"Momentum\", \"Value Investing\", ...]\n",
    "# top3 = get_top3_strategies(financial_strategies, strategy_list)\n",
    "# print(top3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a58865d3-f8e4-4421-b7fe-84a362116125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 20 news articles from TechCrunch\n",
      "https://techcrunch.com/2025/07/28/ai-data-analyst-startup-julius-nabs-10m-seed-round/\n",
      "https://techcrunch.com/2025/07/28/waymo-taps-avis-to-manage-robotaxi-fleet-in-dallas/\n",
      "https://techcrunch.com/2025/07/28/harmonic-the-robinhood-ceos-ai-math-startup-launches-an-ai-chatbot-app/\n",
      "https://techcrunch.com/2025/07/28/flexport-sells-former-freight-unicorn-convoys-tech-two-years-after-buying-it/\n",
      "https://techcrunch.com/2025/07/28/microsoft-edge-is-now-an-ai-browser-with-launch-of-copilot-mode/\n",
      "https://techcrunch.com/2025/07/28/anthropic-unveils-new-rate-limits-to-curb-claude-code-power-users/\n",
      "https://techcrunch.com/2025/07/28/new-york-state-cyber-chief-calls-out-trump-for-cybersecurity-cuts/\n",
      "https://techcrunch.com/2025/07/28/amazon-disputes-report-that-it-raised-prices-of-popular-items-since-trump-took-office/\n",
      "https://techcrunch.com/2025/07/28/why-dispos-co-founder-made-the-leap-from-social-media-to-steelmaking/\n",
      "https://techcrunch.com/2025/07/28/google-chrome-adds-ai-powered-store-summaries-to-help-u-s-shoppers/\n",
      "https://techcrunch.com/2025/07/28/techcrunch-mobility-tesla-vs-gm-a-tale-of-two-earnings/\n",
      "https://techcrunch.com/2025/07/28/tesla-signs-16-5b-deal-with-samsung-to-make-ai-chips/\n",
      "https://techcrunch.com/2025/07/28/20-national-security-experts-urge-trump-administration-to-restrict-nvidia-h20-sales-to-china/\n",
      "https://techcrunch.com/2025/07/28/do-startups-still-need-silicon-valley-hear-from-the-founders-and-funders-challenging-old-assumptions-at-techcrunch-disrupt-2025/\n",
      "https://techcrunch.com/2025/07/28/meet-the-minds-shaping-ai-techcrunch-disrupt-2025-ai-stage-revealed/\n",
      "https://techcrunch.com/2025/07/28/flights-grounded-as-russias-largest-airline-aeroflot-hit-by-cyberattack/\n",
      "https://techcrunch.com/2025/07/27/wizard-of-oz-blown-up-by-ai-for-giant-sphere-screen/\n",
      "https://techcrunch.com/2025/07/27/itch-io-is-the-latest-marketplace-to-crack-down-on-adult-games/\n",
      "https://techcrunch.com/2025/07/27/doge-has-built-an-ai-tool-to-slash-federal-regulations/\n",
      "https://techcrunch.com/2025/07/26/u-k-starts-enforcing-online-age-check-rules/\n"
     ]
    }
   ],
   "source": [
    "get_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7063f749-c5aa-499f-94ab-d0ee2754637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e09fdcc2-8b5a-4e96-8392-9747e91f0297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strategy_store_idx/\n",
      "strategy_store_idx/index.faiss\n",
      "strategy_store_idx/index.pkl\n"
     ]
    }
   ],
   "source": [
    "!tar xzvf strategy_store_idx.tgz\n",
    "historical_store = fa.load_local(\"strategy_store_idx\", embedder, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "082eeaa4-7440-4a33-ab62-346423f8ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('strategy_list.pkl', 'rb') as f:    # ‘rb’ = read in binary mode\n",
    "    strategy_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ca64be0-a44e-4143-954a-8db9adf56f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_list = {}\n",
    "hours_list = {}\n",
    "capital_list = {}\n",
    "timeframe_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "247fd6b0-8708-4013-bb39-ef072c348f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_list[\"1\"] = \"High School or less\"\n",
    "edu_list[\"2\"] = \"Some College or Vocational Training\"\n",
    "edu_list[\"3\"] = \"Bachelor's Degree\"\n",
    "edu_list[\"4\"] = \"Master's or Professional Degree\"\n",
    "edu_list[\"5\"] = \"Doctorate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a64f2e9-09ec-4d40-b1d5-7c18a60e9144",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_list[\"1\"] = \"1 - 3 hrs\"\n",
    "hours_list[\"2\"] = \"3 - 7 hrs\"\n",
    "hours_list[\"3\"] = \"7 - 20 hrs\"\n",
    "hours_list[\"4\"] = \"20 - 40 hrs\"\n",
    "hours_list[\"5\"] = \"40+ hrs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5273e4e2-a2be-4993-b914-d707c79dc35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_list[\"1\"] = \"< $200\"\n",
    "capital_list[\"2\"] = \"$200 - $500\"\n",
    "capital_list[\"3\"] = \"$500 - $2000\"\n",
    "capital_list[\"4\"] = \"$2000 - $10000\"\n",
    "capital_list[\"5\"] = \"$10000+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aec2af05-75b2-44f0-846c-44772f225013",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframe_list[\"1\"] = \"less than a month\"\n",
    "timeframe_list[\"2\"] = \"1 - 6 months\"\n",
    "timeframe_list[\"3\"] = \"6 - 12 months\"\n",
    "timeframe_list[\"4\"] = \"1 - 3 years\"\n",
    "timeframe_list[\"5\"] = \"3+ years\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c13e0edd-cd23-40e2-aa47-5c82fd006c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg1_user[\"Age\"] = \"11\"\n",
    "eg1_assist[\"Age\"] = \"11\"\n",
    "eg2_user[\"Age\"] = \"eleven\"\n",
    "eg2_assist[\"Age\"] = \"11\"\n",
    "eg3_user[\"Age\"] = \"ghost\"\n",
    "eg3_assist[\"Age\"] = \"Invalid\"\n",
    "return_info[\"Age\"] = \"return only one number\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06587ac3-a683-46c3-8856-18fca7cb450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg1_user[\"Country\"] = \"antigua\"\n",
    "eg1_assist[\"Country\"] = \"Antigua and Barbuda\"\n",
    "eg2_user[\"Country\"] = \"I am from Barbados\"\n",
    "eg2_assist[\"Country\"] = \"Barbados\"\n",
    "eg3_user[\"Country\"] = \"Asia\"\n",
    "eg3_assist[\"Country\"] = \"Invalid\"\n",
    "return_info[\"Country\"] = \"return a string containing one existing country\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "278217b8-f564-40d6-9749-81ee6ae0e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg1_user[\"Education\"] = \"3\"\n",
    "eg1_assist[\"Education\"] = \"3\"\n",
    "eg2_user[\"Education\"] = \"Two\"\n",
    "eg2_assist[\"Education\"] = \"2\"\n",
    "eg3_user[\"Education\"] = \"Pluto\"\n",
    "eg3_assist[\"Education\"] = \"Invalid\"\n",
    "options[\"Education\"] =  \"1. High School or less\\n2. Some College or Vocational Training\\n3. Bachelor's Degree\\n4. Master's or Professional Degree\\n5. Doctorate \"\n",
    "return_info[\"Education\"] = \"return only one number\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "685841cf-cc58-4c7e-8d73-74e51710188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg1_user[\"Skills\"] = \"programming\"\n",
    "eg1_assist[\"Skills\"] = \"Programming\"\n",
    "eg2_user[\"Skills\"] = \"cooking, Marketing, proGramming\"\n",
    "eg2_assist[\"Skills\"] = \"Cooking, Marketing, Programming\"\n",
    "eg3_user[\"Skills\"] = \"No\"\n",
    "eg3_assist[\"Skills\"] = \"Invalid\"\n",
    "return_info[\"Skills\"] = \"return a string of comma seperated list of skills with First Letter of each skill capitalised and lowercase for rest letters.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0374c8f2-b8aa-4a2b-b5af-e922b540be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg1_user[\"Hours\"] = \"3\"\n",
    "eg1_assist[\"Hours\"] = \"3\"\n",
    "eg2_user[\"Hours\"] = \"Two\"\n",
    "eg2_assist[\"Hours\"] = \"2\"\n",
    "eg3_user[\"Hours\"] = \"Pluto\"\n",
    "eg3_assist[\"Hours\"] = \"Invalid\"\n",
    "options[\"Hours\"] =  \"1. 1 - 3 hrs\\n2. 3 - 7 hrs\\n3. 7 - 20 hrs\\n4. 20 - 40 hrs\\n5. 40+ hrs\"\n",
    "return_info[\"Hours\"] = \"return only one number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f58a850a-73d3-4df8-bfec-b0fa70b10946",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg1_user[\"Capital\"] = \"3\"\n",
    "eg1_assist[\"Capital\"] = \"3\"\n",
    "eg2_user[\"Capital\"] = \"Two\"\n",
    "eg2_assist[\"Capital\"] = \"2\"\n",
    "eg3_user[\"Capital\"] = \"Pluto\"\n",
    "eg3_assist[\"Capital\"] = \"Invalid\"\n",
    "options[\"Capital\"] =  \"1. < $200\\n2. $200 - $500\\n3. $500 - $2000\\n4. $2000 - $10000\\n5. $10000+\"\n",
    "return_info[\"Capital\"] = \"return only one number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9660fb99-3651-4f97-b880-5c85fdc8c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg1_user[\"TimeFrame\"] = \"3\"\n",
    "eg1_assist[\"TimeFrame\"] = \"3\"\n",
    "eg2_user[\"TimeFrame\"] = \"Two\"\n",
    "eg2_assist[\"TimeFrame\"] = \"2\"\n",
    "eg3_user[\"TimeFrame\"] = \"Pluto\"\n",
    "eg3_assist[\"TimeFrame\"] = \"Invalid\"\n",
    "options[\"TimeFrame\"] =  \"1. less than a month\\n2. 1 - 6 months\\n3. 6 - 12 months\\n4. 1 - 3 years\\n5. 3+ years\"\n",
    "return_info[\"TimeFrame\"] = \"return only one number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0b5a487-865e-464d-894b-7407ff9a0948",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg1_user[\"Profile\"] = \"1\"\n",
    "eg1_assist[\"Profile\"] = \"1\"\n",
    "eg2_user[\"Profile\"] = \"Two\"\n",
    "eg2_assist[\"Profile\"] = \"2\"\n",
    "eg3_user[\"Profile\"] = \"Pluto\"\n",
    "eg3_assist[\"Profile\"] = \"Invalid\"\n",
    "options[\"Profile\"] =  \"1. yes\\n2. no\"\n",
    "return_info[\"Profile\"] = \"return only one number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6b8c0fc-19d7-4b21-b872-c504e475b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt0 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", sys_msg0),\n",
    "    (\"user\", \"[[{eg1_user}]]\"),\n",
    "    (\"assistant\", \"{eg1_assist}\"),\n",
    "    (\"user\", \"[[{eg2_user}]]\"),\n",
    "    (\"assistant\", \"{eg2_assist}\"),\n",
    "    (\"user\", \"[[{eg3_user}]]\"),\n",
    "    (\"assistant\", \"{eg3_assist}\"),\n",
    "    (\"user\", \"[[{input}]]\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a40cef1d-67fc-4506-a2d3-c74ed5c5f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", sys_msg1),\n",
    "    (\"user\", \"[[{eg1_user}]]\"),\n",
    "    (\"assistant\", \"{eg1_assist}\"),\n",
    "    (\"user\", \"[[{eg2_user}]]\"),\n",
    "    (\"assistant\", \"{eg2_assist}\"),\n",
    "    (\"user\", \"[[{eg3_user}]]\"),\n",
    "    (\"assistant\", \"{eg3_assist}\"),\n",
    "    (\"user\", \"[[{input}]]\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0184e77c-4af9-41e4-9d10-b4db63101068",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", sys_msg2),\n",
    "    (\"user\", \"[[{eg1_user}]]\"),\n",
    "    (\"assistant\", \"{eg1_assist}\"),\n",
    "    (\"user\", \"[[{eg2_user}]]\"),\n",
    "    (\"assistant\", \"{eg2_assist}\"),\n",
    "    (\"user\", \"[[{eg3_user}]]\"),\n",
    "    (\"assistant\", \"{eg3_assist}\"),\n",
    "    (\"user\", \"[[{input}]]\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b624d87-cae4-40b7-87ea-d70efd9ce771",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm0 = prompt0 | instruct_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a02bd53-13c8-461e-93ee-f6f634ea6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm1 = prompt0 | instruct_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "caa4ecb2-e1ac-47c6-9707-974e00b6a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2 = prompt1 | instruct_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "297bd03b-304a-4c8d-819c-300be31fe20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm3 = prompt0 | instruct_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5106e71-d0a1-44d1-894e-c3bec75531b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm4 = prompt2 | instruct_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6695b21a-1cf5-4ad0-bc33-ecc795371109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(llm0.invoke({'info':'Age','return_info':return_info[\"Age\"],'eg1_user':eg1_user[\"Age\"],'eg1_assist':eg1_assist[\"Age\"],'eg2_user':eg2_user[\"Age\"],'eg2_assist':eg2_assist[\"Age\"],'eg3_user':eg3_user[\"Age\"],'eg3_assist':eg3_assist[\"Age\"],'input':\"36\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f32f1daf-1943-4b51-bfed-423ec962e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = 0 #keep track of where we are in the information gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fb0c14e-d9ef-40cb-bd83-184b56306c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_rep = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da050670-ab61-4e33-83ff-29f25a365516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_llm(message, history):\n",
    "    global phase, phase_rep\n",
    "    try:\n",
    "        yield {\"role\": \"user\", \"content\": message}\n",
    "\n",
    "        buffer = \"\"\n",
    "        if phase == 0:\n",
    "            chat_gen = llm0.invoke({\n",
    "                'info': 'Age',\n",
    "                'return_info': return_info[\"Age\"],\n",
    "                'eg1_user': eg1_user[\"Age\"],\n",
    "                'eg1_assist': eg1_assist[\"Age\"],\n",
    "                'eg2_user': eg2_user[\"Age\"],\n",
    "                'eg2_assist': eg2_assist[\"Age\"],\n",
    "                'eg3_user': eg3_user[\"Age\"],\n",
    "                'eg3_assist': eg3_assist[\"Age\"],\n",
    "                'input': message\n",
    "            })\n",
    "            if chat_gen == 'Invalid':\n",
    "                phase_rep += 1\n",
    "                yield {\"role\": \"assistant\", \"content\": \"Invalid Age. Can you enter a valid age?\"}\n",
    "            else:\n",
    "                phase = 1\n",
    "                phase_rep = 0\n",
    "                user_profile[\"Age\"] = chat_gen\n",
    "                yield {\"role\": \"assistant\", \"content\": \"Thanks. What country are you in?\"}\n",
    "                \n",
    "\n",
    "        elif phase == 1:\n",
    "            chat_gen = llm1.invoke({\n",
    "                'info': 'Country',\n",
    "                'return_info': return_info[\"Country\"],\n",
    "                'eg1_user': eg1_user[\"Country\"],\n",
    "                'eg1_assist': eg1_assist[\"Country\"],\n",
    "                'eg2_user': eg2_user[\"Country\"],\n",
    "                'eg2_assist': eg2_assist[\"Country\"],\n",
    "                'eg3_user': eg3_user[\"Country\"],\n",
    "                'eg3_assist': eg3_assist[\"Country\"],\n",
    "                'input': message\n",
    "            })\n",
    "            if chat_gen == 'Invalid':\n",
    "                phase_rep += 1\n",
    "                yield {\"role\": \"assistant\", \"content\": \"Invalid Country. Can you enter a valid Country?\"}\n",
    "            else:\n",
    "                phase = 2\n",
    "                phase_rep = 0\n",
    "                user_profile[\"Country\"] = chat_gen\n",
    "                edu_options = options['Education']\n",
    "                yield {\"role\": \"assistant\", \"content\": f\"Thanks. Can you select your highest level of education(enter item number)?\\n{edu_options}\"}\n",
    "        elif phase == 2:\n",
    "            chat_gen = llm2.invoke({\n",
    "                'info': 'Education',\n",
    "                'return_info': return_info[\"Education\"],\n",
    "                'eg1_user': eg1_user[\"Education\"],\n",
    "                'eg1_assist': eg1_assist[\"Education\"],\n",
    "                'eg2_user': eg2_user[\"Education\"],\n",
    "                'eg2_assist': eg2_assist[\"Education\"],\n",
    "                'eg3_user': eg3_user[\"Education\"],\n",
    "                'eg3_assist': eg3_assist[\"Education\"],\n",
    "                'options': options[\"Education\"],\n",
    "                'input': message\n",
    "            })\n",
    "            if chat_gen == 'Invalid':\n",
    "                phase_rep += 1\n",
    "                edu_options = options['Education']\n",
    "                yield {\"role\": \"assistant\", \"content\": f\"Invalid Highest Level of Education. Can you select your highest level of education(enter item number)?\\n{edu_options}\"}\n",
    "            else:\n",
    "                phase = 3\n",
    "                phase_rep = 0\n",
    "                user_profile[\"Education\"] = chat_gen\n",
    "                yield {\"role\": \"assistant\", \"content\": \"Thanks. Can you enter skills that you possess separated by commas? e.g. Marketing, Programming, Writing etc.\"}\n",
    "        elif phase == 3:\n",
    "            chat_gen = llm3.invoke({\n",
    "                'info': 'Skills',\n",
    "                'return_info': return_info[\"Skills\"],\n",
    "                'eg1_user': eg1_user[\"Skills\"],\n",
    "                'eg1_assist': eg1_assist[\"Skills\"],\n",
    "                'eg2_user': eg2_user[\"Skills\"],\n",
    "                'eg2_assist': eg2_assist[\"Skills\"],\n",
    "                'eg3_user': eg3_user[\"Skills\"],\n",
    "                'eg3_assist': eg3_assist[\"Skills\"],\n",
    "                'input': message\n",
    "            })\n",
    "            if chat_gen == 'Invalid':\n",
    "                phase_rep += 1\n",
    "                yield {\"role\": \"assistant\", \"content\": \"Invalid Skills. Can you enter skills that you possess separated by commas? e.g. Marketing, Programming, Writing etc.\"}\n",
    "            else:\n",
    "                phase = 4\n",
    "                phase_rep = 0\n",
    "                user_profile[\"Skills\"] = chat_gen\n",
    "                hours_options = options['Hours']\n",
    "                yield {\"role\": \"assistant\", \"content\": f\"Thanks. How much free time per week do you have available to dedicate to an investment(enter item number)?\\n{hours_options}\"}\n",
    "        elif phase == 4:\n",
    "            chat_gen = llm2.invoke({\n",
    "                'info': 'Available Free Time',\n",
    "                'return_info': return_info[\"Hours\"],\n",
    "                'eg1_user': eg1_user[\"Hours\"],\n",
    "                'eg1_assist': eg1_assist[\"Hours\"],\n",
    "                'eg2_user': eg2_user[\"Hours\"],\n",
    "                'eg2_assist': eg2_assist[\"Hours\"],\n",
    "                'eg3_user': eg3_user[\"Hours\"],\n",
    "                'eg3_assist': eg3_assist[\"Hours\"],\n",
    "                'options': options[\"Hours\"],\n",
    "                'input': message\n",
    "            })\n",
    "            if chat_gen == 'Invalid':\n",
    "                phase_rep += 1\n",
    "                hours_options = options['Hours']\n",
    "                yield {\"role\": \"assistant\", \"content\": f\"Invalid Option selected. How much free time per week do you have available to dedicate to an investment(enter item number)?\\n{hours_options}\"}\n",
    "            else:\n",
    "                phase = 5\n",
    "                phase_rep = 0\n",
    "                user_profile[\"Hours\"] = chat_gen\n",
    "                capital_options = options['Capital']\n",
    "                yield {\"role\": \"assistant\", \"content\": f\"Thanks. Capital available to pursue an investment(enter item number)?\\n{capital_options}\"}\n",
    "        elif phase == 5:\n",
    "            chat_gen = llm2.invoke({\n",
    "                'info': 'Available Capital',\n",
    "                'return_info': return_info[\"Capital\"],\n",
    "                'eg1_user': eg1_user[\"Capital\"],\n",
    "                'eg1_assist': eg1_assist[\"Capital\"],\n",
    "                'eg2_user': eg2_user[\"Capital\"],\n",
    "                'eg2_assist': eg2_assist[\"Capital\"],\n",
    "                'eg3_user': eg3_user[\"Capital\"],\n",
    "                'eg3_assist': eg3_assist[\"Capital\"],\n",
    "                'options': options[\"Capital\"],\n",
    "                'input': message\n",
    "            })\n",
    "            if chat_gen == 'Invalid':\n",
    "                phase_rep += 1\n",
    "                capital_options = options['Capital']\n",
    "                yield {\"role\": \"assistant\", \"content\": f\"Invalid Option selected. Capital available to pursue an investment(enter item number)?\\n{capital_options}\"}\n",
    "            else:\n",
    "                phase = 6\n",
    "                phase_rep = 0\n",
    "                user_profile[\"Capital\"] = chat_gen\n",
    "                tf_options = options[\"TimeFrame\"]\n",
    "                yield {\"role\": \"assistant\", \"content\": f\"Thanks. Expected time frame for the pay off of the investment(enter item number)?\\n{tf_options}\"}        \n",
    "        elif phase == 6:\n",
    "            chat_gen = llm2.invoke({\n",
    "                'info': 'Expected Time Frame for Return on Investment',\n",
    "                'return_info': return_info[\"TimeFrame\"],\n",
    "                'eg1_user': eg1_user[\"TimeFrame\"],\n",
    "                'eg1_assist': eg1_assist[\"TimeFrame\"],\n",
    "                'eg2_user': eg2_user[\"TimeFrame\"],\n",
    "                'eg2_assist': eg2_assist[\"TimeFrame\"],\n",
    "                'eg3_user': eg3_user[\"TimeFrame\"],\n",
    "                'eg3_assist': eg3_assist[\"TimeFrame\"],\n",
    "                'options': options[\"TimeFrame\"],\n",
    "                'input': message\n",
    "            })\n",
    "            if chat_gen == 'Invalid':\n",
    "                phase_rep += 1\n",
    "                tf_options = options[\"TimeFrame\"]\n",
    "                yield {\"role\": \"assistant\", \"content\": f\"Invalid option selected. Expected time frame for the pay off of the investment(enter item number)?\\n{tf_options}\"}\n",
    "            else:\n",
    "                phase = 7\n",
    "                phase_rep = 0\n",
    "                user_profile[\"TimeFrame\"] = chat_gen\n",
    "                profile_state = f\"Age: {user_profile['Age']}\\nCountry: {user_profile['Country']}\\nEducation: {edu_list[user_profile['Education']]}\\nSkills: {user_profile['Skills']}\\nFree Time: {hours_list[user_profile['Hours']]}\\nCapital: {capital_list[user_profile['Capital']]}\\nTime Frame: {timeframe_list[user_profile['TimeFrame']]}\\n\"\n",
    "                yield {\"role\": \"assistant\", \"content\": f\"Thanks. This is your current profile:\\n{profile_state}\\nAre you satisfy with the profile? Enter 1 for yes or 2 if you desire to re-enter profile.\"}        \n",
    "        elif phase == 7:\n",
    "            chat_gen = llm4.invoke({\n",
    "                'info': 'Expected Time Frame for Return on Investment',\n",
    "                'return_info': return_info[\"Profile\"],\n",
    "                'eg1_user': eg1_user[\"Profile\"],\n",
    "                'eg1_assist': eg1_assist[\"Profile\"],\n",
    "                'eg2_user': eg2_user[\"Profile\"],\n",
    "                'eg2_assist': eg2_assist[\"Profile\"],\n",
    "                'eg3_user': eg3_user[\"Profile\"],\n",
    "                'eg3_assist': eg3_assist[\"Profile\"],\n",
    "                'options': options[\"Profile\"],\n",
    "                'input': message\n",
    "            })\n",
    "            if chat_gen == 'Invalid':\n",
    "                phase_rep += 1\n",
    "                profile_state = f\"Age: {user_profile['Age']}\\nCountry: {user_profile['Country']}\\nEducation: {edu_list[user_profile['Education']]}\\nSkills: {user_profile['Skills']}\\nFree Time: {hours_list[user_profile['Hours']]}\\nCapital: {capital_list[user_profile['Capital']]}\\nTime Frame: {timeframe_list[user_profile['TimeFrame']]}\\n\"\n",
    "                yield {\"role\": \"assistant\", \"content\": f\"Invalid option selected. This is your current profile:\\n{profile_state}\\nAre you satisfy with the profile? Enter 1 for yes or 2 if you desire to re-enter profile.\"}\n",
    "            else:\n",
    "                phase = 8\n",
    "                phase_rep = 0\n",
    "                if chat_gen == \"2\":\n",
    "                    phase = 0\n",
    "                    yield {\"role\": \"assistant\", \"content\": f\"Thanks. What is your age?\"}\n",
    "                else:\n",
    "                    yield {\"role\": \"assistant\", \"content\": f\"Thinking...\"}\n",
    "        elif phase == 8:\n",
    "            if phase_rep == 0:\n",
    "                profile_state = f\"Age: {user_profile['Age']}\\nCountry: {user_profile['Country']}\\nEducation: {edu_list[user_profile['Education']]}\\nSkills: {user_profile['Skills']}\\nFree Time: {hours_list[user_profile['Hours']]}\\nCapital: {capital_list[user_profile['Capital']]}\\nTime Frame: {timeframe_list[user_profile['TimeFrame']]}\\n\"\n",
    "                combined = process_all_current_events(\"techcrunch\", profile_state)\n",
    "                phase_rep += 1\n",
    "                yield {\"role\": \"assistant\", \"content\": f\"{combined[0]}\"}\n",
    "            elif phase_rep == 1:\n",
    "                texts_to_embed = [item['text'] for item in combined]\n",
    "                current_news_embeddings = embedder.embed_documents(texts_to_embed)\n",
    "                #TODO 7 - Returns a list of tuples containing the index of a historial store embedding, index of a current news embedding and a similarity score\n",
    "                financial_strategies = get_similarity_scores(current_news_embeddings, historical_store)\n",
    "                phase_rep +=1\n",
    "                yield {\"role\": \"assistant\", \"content\": \"Strategies Assembled\"}\n",
    "            else:\n",
    "                #TODO 8 - Return a string with the top 3 recommend strategies\n",
    "                top3 = get_top3_strategies(financial_strategies,strategy_list)\n",
    "                yield {\"role\": \"assistant\", \"content\": f\"{top3}\"}\n",
    "                phase = 9\n",
    "                phase_rep = 0\n",
    "            \n",
    "                    \n",
    "            \n",
    "\n",
    "    except Exception as e:\n",
    "        yield {\"role\": \"assistant\", \"content\": f\"Error: {e}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1d47dd1-982f-43a2-bbf5-e5e714ad8946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/gradio/chat_interface.py:328: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'messages', will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://8da09f1355b62441f1.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://8da09f1355b62441f1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://8da09f1355b62441f1.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Properly assign the initial message\n",
    "initial_message = {\"role\": \"assistant\", \"content\": \"I’m Pathwise, your AI financial advisor. I analyze historical patterns and current trends to help improve your financial situation. To begin, may I ask your age?\"}\n",
    "\n",
    "# Assign the chatbot with a list containing one message\n",
    "chatbot = gr.Chatbot(\n",
    "    label=\"Chat History\",\n",
    "    value=[initial_message],  \n",
    "    type=\"messages\"\n",
    ")\n",
    "\n",
    "gr.ChatInterface(\n",
    "    fn=chat_with_llm,\n",
    "    chatbot=chatbot,\n",
    "    title=\"Pathwise – Personalized AI Financial Insights\",\n",
    "    description=\"Discover how historical patterns and real-time financial trends apply to you. Pathwise uses your profile to deliver tailored advice that helps you make smarter money decisions. Let's start by getting to know you.\",\n",
    ").queue().launch(share=True, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649083f7-4c28-4144-ac06-3de3cdcf105b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
